{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels                  Id         label\n",
      "count  30336.000000  30336.000000\n",
      "mean   15167.500000      0.077664\n",
      "std     8757.393219      0.267646\n",
      "min        0.000000      0.000000\n",
      "25%     7583.750000      0.000000\n",
      "50%    15167.500000      0.000000\n",
      "75%    22751.250000      0.000000\n",
      "max    30335.000000      1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, BatchNormalization, Conv1D, Multiply, Activation, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "## Below path hardcoded. TODO: Change this\n",
    "prefix_path = '..'\n",
    "\n",
    "labels = pd.read_csv(prefix_path + '/train_kaggle.csv')\n",
    "\n",
    "print('Labels', labels.describe())\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "## ones count kept to balance number of zeros and ones in data to be equal\n",
    "ones = len(labels.loc[labels['label']==1])\n",
    "\n",
    "max_len = 350\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape (4711, 350, 40)\n",
      "y shape (4711,)\n"
     ]
    }
   ],
   "source": [
    "## For each sample in the file\n",
    "for index, train_label in labels.iterrows():\n",
    "    label = train_label['label']\n",
    "    ## Checking below if number of zeros matches total number of ones, then stop adding zeros to data\n",
    "    if label == 0 and ones > 0:\n",
    "        ones = ones - 1\n",
    "    if ones == 0 and label == 0:\n",
    "        continue\n",
    "    ## zeros_array used to keep the maximum number of sequences constant to max_len\n",
    "    zeros_array = np.zeros((max_len, 40))\n",
    "\n",
    "    ## features is a (N, 40) matrix\n",
    "    features = np.load(prefix_path + '/train/train/' + str(train_label['Id']) + '.npy')\n",
    "    \n",
    "    ## We add it to zeros_array to make all samples as (400, 40) matrix\n",
    "    zeros_array[0:len(features)] = features\n",
    "\n",
    "\n",
    "    ## For each feature, we find average of all values and replace all NaN with that value\n",
    "    for feature in range(40):\n",
    "        average_value = np.average(zeros_array[:feature][np.nan_to_num(zeros_array[:feature]) != 0])\n",
    "        zeros_array[:feature] = np.nan_to_num(zeros_array[:feature], average_value)\n",
    "\n",
    "    X.append(zeros_array)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.nan_to_num(np.array(X))\n",
    "y = np.array(y)\n",
    "\n",
    "print('X Shape', X.shape)\n",
    "print('y shape', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4711, 40)\n",
      "Score :  0.5015906680805938\n"
     ]
    }
   ],
   "source": [
    "X_2d = np.sum(X, axis=1)\n",
    "\n",
    "print(X_2d.shape)\n",
    "\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_2d, y, test_size=0.20, random_state=4)\n",
    "\n",
    "# clf = AdaBoostClassifier(n_estimators=100).fit(x_train, y_train)\n",
    "# clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5).fit(x_train, y_train)\n",
    "# clf = svm.SVC(gamma='scale').fit(x_train, y_train)\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(15, 10, 5), random_state=1).fit(x_train, y_train)\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "print('Score : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mihir/pythonprojects/cs5228_project/cs5228/venv/lib/python3.6/site-packages/numpy/lib/function_base.py:390: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/mihir/pythonprojects/cs5228_project/cs5228/venv/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "test_X = []\n",
    "for fileno in range(10000):\n",
    "    ## zeros_array used to keep the maximum number of sequences constant to max_len\n",
    "    zeros_array = np.zeros((max_len, 40))\n",
    "\n",
    "    ## features is a (N, 40) matrix\n",
    "    features = np.load(prefix_path + '/test/test/' + str(fileno) + '.npy')\n",
    "    ## We add it to zeros_array to make all samples as (400, 40) matrix\n",
    "    zeros_array[0:len(features)] = features\n",
    "\n",
    "    ## For each feature, we find average of all values and replace all NaN with that value\n",
    "    for feature in range(40):\n",
    "        average_value = np.average(zeros_array[:feature][np.nan_to_num(zeros_array[:feature]) != 0])\n",
    "        zeros_array[:feature] = np.nan_to_num(zeros_array[:feature], average_value)\n",
    "\n",
    "    test_X.append(zeros_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 40)\n",
      "(10000,)\n",
      "Ones  10000\n"
     ]
    }
   ],
   "source": [
    "test_X = np.nan_to_num(np.array(test_X))\n",
    "test_X_2d = np.sum(test_X, axis=1)\n",
    "\n",
    "print(test_X_2d.shape)\n",
    "\n",
    "test_Y_2d = clf.predict(test_X_2d)\n",
    "print(test_Y_2d.shape)\n",
    "print('Ones ', np.count_nonzero(test_Y_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Id': np.array([i for i in range(10000)]), 'Predicted': test_Y_2d})\n",
    "\n",
    "df.to_csv('submission.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
